"""
Usage:
    spike_study.py <inputfile> <outpath> [options]

Options:
    -n <cores>       Cores to use [default: 1]
    -v <verbosity>   Verbosity [default: 10]
    -m <min_adc>  Maximum number of Events [default: 0]

apply TimelapseCalibration for given .dat file(s):
inputfile: .pickle file generated by apply_timelapse_calibration.py
outpath: path where to put generated data.pickle
"""

from joblib import Parallel, delayed
from docopt import docopt
# import joblib
import numpy as np
# import matplotlib.pyplot as plt
import pickle

def find_spikes(event):
    """Find spike and return characteristics"""
    # spikes = None
    spikes = []
    for pixel in range(7):
        for channel in event.data.dtype.names:
            for adc in event.data[pixel][channel][5:36]:
                if adc >= min_adc:
                    sample_id = np.where(event.data[pixel][channel] == adc)
                    spikes.append([adc, pixel, channel, event.header.event_counter, event.header.stop_cells[pixel][channel], sample_id[0][0]])
    return spikes


if __name__ == '__main__':
    args = docopt(
        __doc__, version='Dragon Board spike study software v.1.0'
    )

    f = open(args['<inputfile>'], "rb")
    calib_events = []
    while 1:
        try:
            calib_events.append(pickle.load(f))
        except EOFError:
            break

    calib_events = list(event for events in calib_events for event in events)

    skip = 500
    calib_events = calib_events[skip:]

    min_adc = int(args['-m']) if args['-m'] else 0

    with Parallel(int(args['-n']), verbose=10) as pool:

        data = list(
            pool(
                delayed(find_spikes)(event) for event in calib_events
            )
        )

    data = list(spike for spike in data if spike)

    flat_data = []
    for spike in data:
        if isinstance(spike[0], list):
            for subspike in spike:
                flat_data.append(subspike)
        else:
            flat_data.append(subspike)
    data = flat_data

    file = (args['<outpath>'] + 'spikes_adc{}_536.pickle'.format(min_adc))
    max_data_size = 10000

    for i in range(int(len(data) / max_data_size)):
        try:
            f = open(file, "rb")
            calib_data = []
            while 1:
                try:
                    calib_data.append(pickle.load(f))
                except EOFError:
                    break
        except:
            pass
        f = open(file, "wb")
        try:
            for data_item in calib_data:
                pickle.dump(data_item, f)
        except:
            pass
        pickle.dump(data[i * max_data_size:(i + 1) * max_data_size - 1], f)
        f.close()

    # adc_data = list(int(adc) for adc in data[:, 0])
    # cell_ids = list(int(stop_cell) for stop_cell in data[:, 4])
    # sample_ids = list(int(sample_id) for sample_id in data[:, 5])
    # pixels = list(int(pixel) for pixel in data[:, 1])
    # channels = list(channel for channel in data[:, 2])
    # hist = dict((channel, channels.count(channel)) for channel in channels)
    # print(hist)
    # [adc, pixel, channel, event_id, cell_id, sample_id]
    # [23,2,"high",502,19] links correctly to the following @skip=500
    # plt.plot(calib_events[1].data[2]["high"][5:36])

    # plt.style.use('ggplot')
    # plt.figure()
    # plt.hist(adc_data, bins=200)
    # plt.hist(cell_ids, bins=4096)
    # plt.hist(sample_ids, bins=40)
    # plt.hist(pixels, bins=20)
    # plt.scatter(cell_ids, sample_ids)
    # plt.scatter(data[:, 4], data[:, 0])
    # plt.title("100k events")
    # plt.show()
