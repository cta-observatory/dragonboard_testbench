"""
Usage:
    extract_spike_data.py <inputfile> <outpath> [options]

Options:
    -n <cores>       Cores to use [default: 1]
    -v <verbosity>   Verbosity [default: 10]
    -m <min_adc>     Minimum ADC count value to be considered [default: 0]
    -s <skip>        Events to be skipped [default: 0]    

extract spike data for given file.pickle
inputfile: .pickle file generated by apply_timelapse_calibration.py
outpath: path where to put generated data.pickle
"""

from joblib import Parallel, delayed
from docopt import docopt
import pickle
import pandas as pd
import os


def find_spikes(event):
    """Find spike and return characteristics"""
    min_sample_id = 5
    max_sample_id = 36
    spikes = []
    for pixel in range(7):
        for channel in event.data.dtype.names:
            for i, adc in enumerate(event.data[pixel][channel][min_sample_id:max_sample_id]):
                if adc >= min_adc:
                    sample_id = i + min_sample_id
                    cell_id = event.header.stop_cells[pixel][channel] + sample_id
                    spikes.append([adc, pixel, channel, event.header.event_counter, cell_id, sample_id, event.time_since_last_readout[pixel][channel][i]])
    return spikes


def read(inputfile):
    """Open and flatten calibrated data"""
    with open(inputfile, "rb") as f:
        calib_events = []
        while True:
            try:
                calib_events.append(pickle.load(f))
            except EOFError:
                break

        calib_events = list(event for events in calib_events for event in events)
    return calib_events


if __name__ == '__main__':
    args = docopt(
        __doc__, version='Dragon Board spike data extraction software v.1.0'
    )

    calib_events = read(args['<inputfile>'])

    min_adc = int(args['-m']) if args['-m'] else 0
    skip = int(args['-s']) if args['-s'] else 0

    calib_events = calib_events[skip:]

    with Parallel(int(args['-n']), verbose=10) as pool:

        data = list(
            pool(
                delayed(find_spikes)(event) for event in calib_events
            )
        )

    data = list(spike for spike in data if spike)

    flat_data = []
    for spike in data:
        if isinstance(spike[0], list):
            for subspike in spike:
                flat_data.append(subspike)
        else:
            flat_data.append(spike)
    data = flat_data

    outpath = os.path.join(args['<outpath>'], 'spikes_adc{}_536.h5'.format(min_adc))

    with pd.HDFStore(outpath, mode='w', comp_level=5, comp_lib='blosc') as store:

        df = pd.DataFrame(data)
        df.columns = ["adc", "pixel", "channel", "event_id", "cell_id", "sample_id", "delta_t"]
        store.append("spikes", df)
